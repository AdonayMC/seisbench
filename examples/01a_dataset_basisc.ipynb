{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75765362",
   "metadata": {},
   "source": [
    "![image](../docs/_static/seisbench_logo_subtitle_outlined.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a2516",
   "metadata": {},
   "source": [
    "# Dataset basics\n",
    "\n",
    "This tutorial introduces the basics of datasets and benchmark datasets in SeisBench. It explains how load a dataset, how to filter it and how to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seisbench\n",
    "import seisbench.data as sbd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67c1dd",
   "metadata": {},
   "source": [
    "### Loading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7c7e8",
   "metadata": {},
   "source": [
    "There are two ways of loading a dataset:\n",
    "1. loading a benchmark dataset\n",
    "2. loading a dataset from disk\n",
    "\n",
    "We will first explore benchmark datasets. Benchmark datasets are represented by classes in SeisBench. When instantiating the class, SeisBench will check if the data is available and otherwise download it. Our example dataset is the DummyDataset, that we load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb01317",
   "metadata": {},
   "source": [
    "When running this command for the first time, the dataset is downloaded. All downloaded data is stored in the SeisBench cache. The location of the cache defaults to `~/.seisbench`, but can be set using the environment variable `SEISBENCH_CACHE_ROOT`. Let's inspect the cache. Depending which commands where used before, it contains at least the directory `datasets`. Inside this directory, each locally available dataset has its own folder. If we look into the folder `dummydataset`, we find two relevant files `metadata.csv` and `waveforms.hdf5`, containing the metadata and the waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Cache root:\", seisbench.cache_root)\n",
    "print(\"Contents:\", os.listdir(seisbench.cache_root))\n",
    "print(\"datasets:\", os.listdir(seisbench.cache_root / \"datasets\"))\n",
    "print(\"dummydataset:\", os.listdir(seisbench.cache_root / \"datasets\" / \"dummydataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e97515",
   "metadata": {},
   "source": [
    "The second way of loading a dataset is loading it from disk by simply providing the path to the directory containing the `metadata.csv` and `waveforms.hdf5` files. We'll demonstrate this using the DummyDataset, even though we'd always recommend loading benchmark dataset through their classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_from_disk = sbd.WaveformDataset(seisbench.cache_root / \"datasets\" / \"dummydataset\")\n",
    "print(dummy_from_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900215bd",
   "metadata": {},
   "source": [
    "### What does a dataset contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c077e3",
   "metadata": {},
   "source": [
    "Each dataset consists of waveforms and the associated metadata. Let's first inspect the metadata. It is represented by a pandas DataFrame and lists for each trace different attributes, describing properties of the source, the trace, the station and possibly the path. When loading a dataset, only the metadata is loaded into memory. The waveforms are loaded on demand. For details, see the section on \"Configuring a dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83938f87",
   "metadata": {},
   "source": [
    "Now let's say, we want to obtain the waveforms associated with trace 3. This can be done using the `get_waveforms` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = data.get_waveforms(3)\n",
    "print(\"waveforms.shape:\", waveforms.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(waveforms.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc855b4d",
   "metadata": {},
   "source": [
    "You can also request waveforms for multiple traces at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = data.get_waveforms([3, 20, 45, 70])\n",
    "print(\"waveforms.shape:\", waveforms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d7b8a",
   "metadata": {},
   "source": [
    "Benchmark dataset contain several special attributes, which simple waveform dataset do not posses. Here are two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a865a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Citation:', data.citation)\n",
    "print('License:', data.license)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20782a",
   "metadata": {},
   "source": [
    "### Filtering a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6aac6",
   "metadata": {},
   "source": [
    "Often, you don't want to use a full dataset, but only parts of it. For this, datasets offer the `filter` method. By default `filter` is applied inplace, but it can also be used to return the desired subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.metadata[\"source_magnitude\"] > 2.5  # Only select events with magnitude above 2.5\n",
    "data.filter(mask)\n",
    "\n",
    "print(data)\n",
    "data.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b56410",
   "metadata": {},
   "source": [
    "A special case of filtering is to access the training, development and test splits of a dataset. Most datasets in SeisBench define those splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset() # Reload to ensure we have the full dataset again\n",
    "\n",
    "train = data.train()\n",
    "dev = data.dev()\n",
    "test = data.test()\n",
    "\n",
    "print(\"Train:\", train)\n",
    "print(\"Dev:\", dev)\n",
    "print(\"Test:\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d94eb",
   "metadata": {},
   "source": [
    "You can also use a shorthand notation to split the dataset into its parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = data.train_dev_test()\n",
    "\n",
    "print(\"Train:\", train)\n",
    "print(\"Dev:\", dev)\n",
    "print(\"Test:\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa7179",
   "metadata": {},
   "source": [
    "### Configuring a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad44c88",
   "metadata": {},
   "source": [
    "Datasets offer a range of configuration options. Here, we are going to explore four of them:\n",
    "\n",
    "- component order\n",
    "- dimension order\n",
    "- sampling rate\n",
    "- waveform caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa98b52",
   "metadata": {},
   "source": [
    "Standard seismometers will consist of three components, commonly vertical (Z), north-south (N) and east-west (E). Depending on your application, you'll need to arrange the components differently. SeisBench can do this automatically. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset(component_order=\"ZNE\")\n",
    "zne_array = data.get_waveforms(0)\n",
    "\n",
    "data = sbd.DummyDataset(component_order=\"NEZ\")\n",
    "nez_array = data.get_waveforms(0)\n",
    "\n",
    "print('ZNE:\\n', zne_array[:, :5])\n",
    "print('NEZ:\\n', nez_array[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68612f",
   "metadata": {},
   "source": [
    "Sometimes, not all components are available. You can use the `missing_components` parameter to define how to handle this case. Check the documentation for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028e2d5",
   "metadata": {},
   "source": [
    "Similar to the component order, the dimension order specifies how to order the dimensions of your data, i.e., the traces (N), the channels (C) and the samples (W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03530ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset(dimension_order=\"NCW\")\n",
    "waveforms = data.get_waveforms([3, 20, 45, 70])\n",
    "print(\"NCW - waveforms.shape:\", waveforms.shape)\n",
    "\n",
    "data = sbd.DummyDataset(dimension_order=\"NWC\")\n",
    "waveforms = data.get_waveforms([3, 20, 45, 70])\n",
    "print(\"NWC - waveforms.shape:\", waveforms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbcebb",
   "metadata": {},
   "source": [
    "Often, applications will require waveforms of a specific sampling rate. By default, seisbench will return data at the sampling rate provided in the dataset. However, you can configure datasets to always return a specific sampling rate, simply by setting it in the constructor. SeisBench will then automatically resample the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035bb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset(sampling_rate=100)\n",
    "waveforms = data.get_waveforms(3)\n",
    "print(\"100 Hz - waveforms.shape:\", waveforms.shape)\n",
    "\n",
    "data = sbd.DummyDataset(sampling_rate=200)\n",
    "waveforms = data.get_waveforms(3)\n",
    "print(\"200 Hz - waveforms.shape:\", waveforms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71f8e0",
   "metadata": {},
   "source": [
    "Alternatively, you can specify the sampling rate in a call to `get_waveforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098894cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset()\n",
    "\n",
    "waveforms = data.get_waveforms(3, sampling_rate=100)\n",
    "print(\"100 Hz - waveforms.shape:\", waveforms.shape)\n",
    "waveforms = data.get_waveforms(3, sampling_rate=200)\n",
    "print(\"200 Hz - waveforms.shape:\", waveforms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2cd511",
   "metadata": {},
   "source": [
    "The last configuration option discussed in this tutorial is waveform caching. As mentioned earlier, loading a dataset actually only loads the metadata into memory, and only reads the waveforms on demand. Depending on your use case, this might not be the optimal scenario. For example, when training a deep learning model, it's usually best to first load all the waveforms into memory, instead of reloading them from disk every epoch. Therefore, SeisBench allows to cache waveforms in memory and to preload them into memory. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sbd.DummyDataset(cache='trace')\n",
    "data.preload_waveforms(pbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88847bc",
   "metadata": {},
   "source": [
    "You can either use a `trace` cache or a `full` cache. Check the documentation for details on these strategies. As a rule of thumb, `trace` should be used if you only need a small fraction of the dataset, while `full` is better suited when using most of the dataset or a full train/dev/test split. Note that `full` might cache traces that you did not actually filter for. On the other side, `full` will have better read performance than `trace` when using many traces.\n",
    "\n",
    "In general, when preloading and filtering a dataset, you should always first filter it and then preload to avoid loading unnecessary traces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438a7d4",
   "metadata": {},
   "source": [
    "### Visualizing a dataset\n",
    "\n",
    "If you have the package `cartopy` installed, you can visualize your dataset using the method `plot_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c49bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9215813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
